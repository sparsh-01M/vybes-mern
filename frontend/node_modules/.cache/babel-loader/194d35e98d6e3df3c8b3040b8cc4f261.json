{"ast":null,"code":"/**\n * @import {Chunk, Event, Token} from 'micromark-util-types'\n */\nimport { ok as assert } from 'devlop';\nimport { splice } from 'micromark-util-chunked';\nimport { codes, types } from 'micromark-util-symbol';\nimport { SpliceBuffer } from './lib/splice-buffer.js'; // Hidden API exposed for testing.\n\nexport { SpliceBuffer } from './lib/splice-buffer.js';\n/**\n * Tokenize subcontent.\n *\n * @param {Array<Event>} eventsArray\n *   List of events.\n * @returns {boolean}\n *   Whether subtokens were found.\n */\n// eslint-disable-next-line complexity\n\nexport function subtokenize(eventsArray) {\n  /** @type {Record<string, number>} */\n  const jumps = {};\n  let index = -1;\n  /** @type {Event} */\n\n  let event;\n  /** @type {number | undefined} */\n\n  let lineIndex;\n  /** @type {number} */\n\n  let otherIndex;\n  /** @type {Event} */\n\n  let otherEvent;\n  /** @type {Array<Event>} */\n\n  let parameters;\n  /** @type {Array<Event>} */\n\n  let subevents;\n  /** @type {boolean | undefined} */\n\n  let more;\n  const events = new SpliceBuffer(eventsArray);\n\n  while (++index < events.length) {\n    while (index in jumps) {\n      index = jumps[index];\n    }\n\n    event = events.get(index); // Add a hook for the GFM tasklist extension, which needs to know if text\n    // is in the first content of a list item.\n\n    if (index && event[1].type === types.chunkFlow && events.get(index - 1)[1].type === types.listItemPrefix) {\n      assert(event[1]._tokenizer, 'expected `_tokenizer` on subtokens');\n      subevents = event[1]._tokenizer.events;\n      otherIndex = 0;\n\n      if (otherIndex < subevents.length && subevents[otherIndex][1].type === types.lineEndingBlank) {\n        otherIndex += 2;\n      }\n\n      if (otherIndex < subevents.length && subevents[otherIndex][1].type === types.content) {\n        while (++otherIndex < subevents.length) {\n          if (subevents[otherIndex][1].type === types.content) {\n            break;\n          }\n\n          if (subevents[otherIndex][1].type === types.chunkText) {\n            subevents[otherIndex][1]._isInFirstContentOfListItem = true;\n            otherIndex++;\n          }\n        }\n      }\n    } // Enter.\n\n\n    if (event[0] === 'enter') {\n      if (event[1].contentType) {\n        Object.assign(jumps, subcontent(events, index));\n        index = jumps[index];\n        more = true;\n      }\n    } // Exit.\n    else if (event[1]._container) {\n      otherIndex = index;\n      lineIndex = undefined;\n\n      while (otherIndex--) {\n        otherEvent = events.get(otherIndex);\n\n        if (otherEvent[1].type === types.lineEnding || otherEvent[1].type === types.lineEndingBlank) {\n          if (otherEvent[0] === 'enter') {\n            if (lineIndex) {\n              events.get(lineIndex)[1].type = types.lineEndingBlank;\n            }\n\n            otherEvent[1].type = types.lineEnding;\n            lineIndex = otherIndex;\n          }\n        } else if (otherEvent[1].type === types.linePrefix || otherEvent[1].type === types.listItemIndent) {// Move past.\n        } else {\n          break;\n        }\n      }\n\n      if (lineIndex) {\n        // Fix position.\n        event[1].end = { ...events.get(lineIndex)[1].start\n        }; // Switch container exit w/ line endings.\n\n        parameters = events.slice(lineIndex, index);\n        parameters.unshift(event);\n        events.splice(lineIndex, index - lineIndex + 1, parameters);\n      }\n    }\n  } // The changes to the `events` buffer must be copied back into the eventsArray\n\n\n  splice(eventsArray, 0, Number.POSITIVE_INFINITY, events.slice(0));\n  return !more;\n}\n/**\n * Tokenize embedded tokens.\n *\n * @param {SpliceBuffer<Event>} events\n *   Events.\n * @param {number} eventIndex\n *   Index.\n * @returns {Record<string, number>}\n *   Gaps.\n */\n\nfunction subcontent(events, eventIndex) {\n  const token = events.get(eventIndex)[1];\n  const context = events.get(eventIndex)[2];\n  let startPosition = eventIndex - 1;\n  /** @type {Array<number>} */\n\n  const startPositions = [];\n  assert(token.contentType, 'expected `contentType` on subtokens');\n  let tokenizer = token._tokenizer;\n\n  if (!tokenizer) {\n    tokenizer = context.parser[token.contentType](token.start);\n\n    if (token._contentTypeTextTrailing) {\n      tokenizer._contentTypeTextTrailing = true;\n    }\n  }\n\n  const childEvents = tokenizer.events;\n  /** @type {Array<[number, number]>} */\n\n  const jumps = [];\n  /** @type {Record<string, number>} */\n\n  const gaps = {};\n  /** @type {Array<Chunk>} */\n\n  let stream;\n  /** @type {Token | undefined} */\n\n  let previous;\n  let index = -1;\n  /** @type {Token | undefined} */\n\n  let current = token;\n  let adjust = 0;\n  let start = 0;\n  const breaks = [start]; // Loop forward through the linked tokens to pass them in order to the\n  // subtokenizer.\n\n  while (current) {\n    // Find the position of the event for this token.\n    while (events.get(++startPosition)[1] !== current) {// Empty.\n    }\n\n    assert(!previous || current.previous === previous, 'expected previous to match');\n    assert(!previous || previous.next === current, 'expected next to match');\n    startPositions.push(startPosition);\n\n    if (!current._tokenizer) {\n      stream = context.sliceStream(current);\n\n      if (!current.next) {\n        stream.push(codes.eof);\n      }\n\n      if (previous) {\n        tokenizer.defineSkip(current.start);\n      }\n\n      if (current._isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = true;\n      }\n\n      tokenizer.write(stream);\n\n      if (current._isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = undefined;\n      }\n    } // Unravel the next token.\n\n\n    previous = current;\n    current = current.next;\n  } // Now, loop back through all events (and linked tokens), to figure out which\n  // parts belong where.\n\n\n  current = token;\n\n  while (++index < childEvents.length) {\n    if ( // Find a void token that includes a break.\n    childEvents[index][0] === 'exit' && childEvents[index - 1][0] === 'enter' && childEvents[index][1].type === childEvents[index - 1][1].type && childEvents[index][1].start.line !== childEvents[index][1].end.line) {\n      assert(current, 'expected a current token');\n      start = index + 1;\n      breaks.push(start); // Help GC.\n\n      current._tokenizer = undefined;\n      current.previous = undefined;\n      current = current.next;\n    }\n  } // Help GC.\n\n\n  tokenizer.events = []; // If there’s one more token (which is the cases for lines that end in an\n  // EOF), that’s perfect: the last point we found starts it.\n  // If there isn’t then make sure any remaining content is added to it.\n\n  if (current) {\n    // Help GC.\n    current._tokenizer = undefined;\n    current.previous = undefined;\n    assert(!current.next, 'expected no next token');\n  } else {\n    breaks.pop();\n  } // Now splice the events from the subtokenizer into the current events,\n  // moving back to front so that splice indices aren’t affected.\n\n\n  index = breaks.length;\n\n  while (index--) {\n    const slice = childEvents.slice(breaks[index], breaks[index + 1]);\n    const start = startPositions.pop();\n    assert(start !== undefined, 'expected a start position when splicing');\n    jumps.push([start, start + slice.length - 1]);\n    events.splice(start, 2, slice);\n  }\n\n  jumps.reverse();\n  index = -1;\n\n  while (++index < jumps.length) {\n    gaps[adjust + jumps[index][0]] = adjust + jumps[index][1];\n    adjust += jumps[index][1] - jumps[index][0] - 1;\n  }\n\n  return gaps;\n}","map":{"version":3,"names":["ok","assert","splice","codes","types","SpliceBuffer","subtokenize","eventsArray","jumps","index","event","lineIndex","otherIndex","otherEvent","parameters","subevents","more","events","length","get","type","chunkFlow","listItemPrefix","_tokenizer","lineEndingBlank","content","chunkText","_isInFirstContentOfListItem","contentType","Object","assign","subcontent","_container","undefined","lineEnding","linePrefix","listItemIndent","end","start","slice","unshift","Number","POSITIVE_INFINITY","eventIndex","token","context","startPosition","startPositions","tokenizer","parser","_contentTypeTextTrailing","childEvents","gaps","stream","previous","current","adjust","breaks","next","push","sliceStream","eof","defineSkip","_gfmTasklistFirstContentOfListItem","write","line","pop","reverse"],"sources":["/Users/sparshsinghal/Downloads/vybes-mern-main/frontend/node_modules/micromark-util-subtokenize/dev/index.js"],"sourcesContent":["/**\n * @import {Chunk, Event, Token} from 'micromark-util-types'\n */\n\nimport {ok as assert} from 'devlop'\nimport {splice} from 'micromark-util-chunked'\nimport {codes, types} from 'micromark-util-symbol'\nimport {SpliceBuffer} from './lib/splice-buffer.js'\n\n// Hidden API exposed for testing.\nexport {SpliceBuffer} from './lib/splice-buffer.js'\n\n/**\n * Tokenize subcontent.\n *\n * @param {Array<Event>} eventsArray\n *   List of events.\n * @returns {boolean}\n *   Whether subtokens were found.\n */\n// eslint-disable-next-line complexity\nexport function subtokenize(eventsArray) {\n  /** @type {Record<string, number>} */\n  const jumps = {}\n  let index = -1\n  /** @type {Event} */\n  let event\n  /** @type {number | undefined} */\n  let lineIndex\n  /** @type {number} */\n  let otherIndex\n  /** @type {Event} */\n  let otherEvent\n  /** @type {Array<Event>} */\n  let parameters\n  /** @type {Array<Event>} */\n  let subevents\n  /** @type {boolean | undefined} */\n  let more\n  const events = new SpliceBuffer(eventsArray)\n\n  while (++index < events.length) {\n    while (index in jumps) {\n      index = jumps[index]\n    }\n\n    event = events.get(index)\n\n    // Add a hook for the GFM tasklist extension, which needs to know if text\n    // is in the first content of a list item.\n    if (\n      index &&\n      event[1].type === types.chunkFlow &&\n      events.get(index - 1)[1].type === types.listItemPrefix\n    ) {\n      assert(event[1]._tokenizer, 'expected `_tokenizer` on subtokens')\n      subevents = event[1]._tokenizer.events\n      otherIndex = 0\n\n      if (\n        otherIndex < subevents.length &&\n        subevents[otherIndex][1].type === types.lineEndingBlank\n      ) {\n        otherIndex += 2\n      }\n\n      if (\n        otherIndex < subevents.length &&\n        subevents[otherIndex][1].type === types.content\n      ) {\n        while (++otherIndex < subevents.length) {\n          if (subevents[otherIndex][1].type === types.content) {\n            break\n          }\n\n          if (subevents[otherIndex][1].type === types.chunkText) {\n            subevents[otherIndex][1]._isInFirstContentOfListItem = true\n            otherIndex++\n          }\n        }\n      }\n    }\n\n    // Enter.\n    if (event[0] === 'enter') {\n      if (event[1].contentType) {\n        Object.assign(jumps, subcontent(events, index))\n        index = jumps[index]\n        more = true\n      }\n    }\n    // Exit.\n    else if (event[1]._container) {\n      otherIndex = index\n      lineIndex = undefined\n\n      while (otherIndex--) {\n        otherEvent = events.get(otherIndex)\n\n        if (\n          otherEvent[1].type === types.lineEnding ||\n          otherEvent[1].type === types.lineEndingBlank\n        ) {\n          if (otherEvent[0] === 'enter') {\n            if (lineIndex) {\n              events.get(lineIndex)[1].type = types.lineEndingBlank\n            }\n\n            otherEvent[1].type = types.lineEnding\n            lineIndex = otherIndex\n          }\n        } else if (\n          otherEvent[1].type === types.linePrefix ||\n          otherEvent[1].type === types.listItemIndent\n        ) {\n          // Move past.\n        } else {\n          break\n        }\n      }\n\n      if (lineIndex) {\n        // Fix position.\n        event[1].end = {...events.get(lineIndex)[1].start}\n\n        // Switch container exit w/ line endings.\n        parameters = events.slice(lineIndex, index)\n        parameters.unshift(event)\n        events.splice(lineIndex, index - lineIndex + 1, parameters)\n      }\n    }\n  }\n\n  // The changes to the `events` buffer must be copied back into the eventsArray\n  splice(eventsArray, 0, Number.POSITIVE_INFINITY, events.slice(0))\n  return !more\n}\n\n/**\n * Tokenize embedded tokens.\n *\n * @param {SpliceBuffer<Event>} events\n *   Events.\n * @param {number} eventIndex\n *   Index.\n * @returns {Record<string, number>}\n *   Gaps.\n */\nfunction subcontent(events, eventIndex) {\n  const token = events.get(eventIndex)[1]\n  const context = events.get(eventIndex)[2]\n  let startPosition = eventIndex - 1\n  /** @type {Array<number>} */\n  const startPositions = []\n  assert(token.contentType, 'expected `contentType` on subtokens')\n\n  let tokenizer = token._tokenizer\n\n  if (!tokenizer) {\n    tokenizer = context.parser[token.contentType](token.start)\n\n    if (token._contentTypeTextTrailing) {\n      tokenizer._contentTypeTextTrailing = true\n    }\n  }\n\n  const childEvents = tokenizer.events\n  /** @type {Array<[number, number]>} */\n  const jumps = []\n  /** @type {Record<string, number>} */\n  const gaps = {}\n  /** @type {Array<Chunk>} */\n  let stream\n  /** @type {Token | undefined} */\n  let previous\n  let index = -1\n  /** @type {Token | undefined} */\n  let current = token\n  let adjust = 0\n  let start = 0\n  const breaks = [start]\n\n  // Loop forward through the linked tokens to pass them in order to the\n  // subtokenizer.\n  while (current) {\n    // Find the position of the event for this token.\n    while (events.get(++startPosition)[1] !== current) {\n      // Empty.\n    }\n\n    assert(\n      !previous || current.previous === previous,\n      'expected previous to match'\n    )\n    assert(!previous || previous.next === current, 'expected next to match')\n\n    startPositions.push(startPosition)\n\n    if (!current._tokenizer) {\n      stream = context.sliceStream(current)\n\n      if (!current.next) {\n        stream.push(codes.eof)\n      }\n\n      if (previous) {\n        tokenizer.defineSkip(current.start)\n      }\n\n      if (current._isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = true\n      }\n\n      tokenizer.write(stream)\n\n      if (current._isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = undefined\n      }\n    }\n\n    // Unravel the next token.\n    previous = current\n    current = current.next\n  }\n\n  // Now, loop back through all events (and linked tokens), to figure out which\n  // parts belong where.\n  current = token\n\n  while (++index < childEvents.length) {\n    if (\n      // Find a void token that includes a break.\n      childEvents[index][0] === 'exit' &&\n      childEvents[index - 1][0] === 'enter' &&\n      childEvents[index][1].type === childEvents[index - 1][1].type &&\n      childEvents[index][1].start.line !== childEvents[index][1].end.line\n    ) {\n      assert(current, 'expected a current token')\n      start = index + 1\n      breaks.push(start)\n      // Help GC.\n      current._tokenizer = undefined\n      current.previous = undefined\n      current = current.next\n    }\n  }\n\n  // Help GC.\n  tokenizer.events = []\n\n  // If there’s one more token (which is the cases for lines that end in an\n  // EOF), that’s perfect: the last point we found starts it.\n  // If there isn’t then make sure any remaining content is added to it.\n  if (current) {\n    // Help GC.\n    current._tokenizer = undefined\n    current.previous = undefined\n    assert(!current.next, 'expected no next token')\n  } else {\n    breaks.pop()\n  }\n\n  // Now splice the events from the subtokenizer into the current events,\n  // moving back to front so that splice indices aren’t affected.\n  index = breaks.length\n\n  while (index--) {\n    const slice = childEvents.slice(breaks[index], breaks[index + 1])\n    const start = startPositions.pop()\n    assert(start !== undefined, 'expected a start position when splicing')\n    jumps.push([start, start + slice.length - 1])\n    events.splice(start, 2, slice)\n  }\n\n  jumps.reverse()\n  index = -1\n\n  while (++index < jumps.length) {\n    gaps[adjust + jumps[index][0]] = adjust + jumps[index][1]\n    adjust += jumps[index][1] - jumps[index][0] - 1\n  }\n\n  return gaps\n}\n"],"mappings":"AAAA;AACA;AACA;AAEA,SAAQA,EAAE,IAAIC,MAAd,QAA2B,QAA3B;AACA,SAAQC,MAAR,QAAqB,wBAArB;AACA,SAAQC,KAAR,EAAeC,KAAf,QAA2B,uBAA3B;AACA,SAAQC,YAAR,QAA2B,wBAA3B,C,CAEA;;AACA,SAAQA,YAAR,QAA2B,wBAA3B;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASC,WAAT,CAAqBC,WAArB,EAAkC;EACvC;EACA,MAAMC,KAAK,GAAG,EAAd;EACA,IAAIC,KAAK,GAAG,CAAC,CAAb;EACA;;EACA,IAAIC,KAAJ;EACA;;EACA,IAAIC,SAAJ;EACA;;EACA,IAAIC,UAAJ;EACA;;EACA,IAAIC,UAAJ;EACA;;EACA,IAAIC,UAAJ;EACA;;EACA,IAAIC,SAAJ;EACA;;EACA,IAAIC,IAAJ;EACA,MAAMC,MAAM,GAAG,IAAIZ,YAAJ,CAAiBE,WAAjB,CAAf;;EAEA,OAAO,EAAEE,KAAF,GAAUQ,MAAM,CAACC,MAAxB,EAAgC;IAC9B,OAAOT,KAAK,IAAID,KAAhB,EAAuB;MACrBC,KAAK,GAAGD,KAAK,CAACC,KAAD,CAAb;IACD;;IAEDC,KAAK,GAAGO,MAAM,CAACE,GAAP,CAAWV,KAAX,CAAR,CAL8B,CAO9B;IACA;;IACA,IACEA,KAAK,IACLC,KAAK,CAAC,CAAD,CAAL,CAASU,IAAT,KAAkBhB,KAAK,CAACiB,SADxB,IAEAJ,MAAM,CAACE,GAAP,CAAWV,KAAK,GAAG,CAAnB,EAAsB,CAAtB,EAAyBW,IAAzB,KAAkChB,KAAK,CAACkB,cAH1C,EAIE;MACArB,MAAM,CAACS,KAAK,CAAC,CAAD,CAAL,CAASa,UAAV,EAAsB,oCAAtB,CAAN;MACAR,SAAS,GAAGL,KAAK,CAAC,CAAD,CAAL,CAASa,UAAT,CAAoBN,MAAhC;MACAL,UAAU,GAAG,CAAb;;MAEA,IACEA,UAAU,GAAGG,SAAS,CAACG,MAAvB,IACAH,SAAS,CAACH,UAAD,CAAT,CAAsB,CAAtB,EAAyBQ,IAAzB,KAAkChB,KAAK,CAACoB,eAF1C,EAGE;QACAZ,UAAU,IAAI,CAAd;MACD;;MAED,IACEA,UAAU,GAAGG,SAAS,CAACG,MAAvB,IACAH,SAAS,CAACH,UAAD,CAAT,CAAsB,CAAtB,EAAyBQ,IAAzB,KAAkChB,KAAK,CAACqB,OAF1C,EAGE;QACA,OAAO,EAAEb,UAAF,GAAeG,SAAS,CAACG,MAAhC,EAAwC;UACtC,IAAIH,SAAS,CAACH,UAAD,CAAT,CAAsB,CAAtB,EAAyBQ,IAAzB,KAAkChB,KAAK,CAACqB,OAA5C,EAAqD;YACnD;UACD;;UAED,IAAIV,SAAS,CAACH,UAAD,CAAT,CAAsB,CAAtB,EAAyBQ,IAAzB,KAAkChB,KAAK,CAACsB,SAA5C,EAAuD;YACrDX,SAAS,CAACH,UAAD,CAAT,CAAsB,CAAtB,EAAyBe,2BAAzB,GAAuD,IAAvD;YACAf,UAAU;UACX;QACF;MACF;IACF,CAxC6B,CA0C9B;;;IACA,IAAIF,KAAK,CAAC,CAAD,CAAL,KAAa,OAAjB,EAA0B;MACxB,IAAIA,KAAK,CAAC,CAAD,CAAL,CAASkB,WAAb,EAA0B;QACxBC,MAAM,CAACC,MAAP,CAActB,KAAd,EAAqBuB,UAAU,CAACd,MAAD,EAASR,KAAT,CAA/B;QACAA,KAAK,GAAGD,KAAK,CAACC,KAAD,CAAb;QACAO,IAAI,GAAG,IAAP;MACD;IACF,CAND,CAOA;IAPA,KAQK,IAAIN,KAAK,CAAC,CAAD,CAAL,CAASsB,UAAb,EAAyB;MAC5BpB,UAAU,GAAGH,KAAb;MACAE,SAAS,GAAGsB,SAAZ;;MAEA,OAAOrB,UAAU,EAAjB,EAAqB;QACnBC,UAAU,GAAGI,MAAM,CAACE,GAAP,CAAWP,UAAX,CAAb;;QAEA,IACEC,UAAU,CAAC,CAAD,CAAV,CAAcO,IAAd,KAAuBhB,KAAK,CAAC8B,UAA7B,IACArB,UAAU,CAAC,CAAD,CAAV,CAAcO,IAAd,KAAuBhB,KAAK,CAACoB,eAF/B,EAGE;UACA,IAAIX,UAAU,CAAC,CAAD,CAAV,KAAkB,OAAtB,EAA+B;YAC7B,IAAIF,SAAJ,EAAe;cACbM,MAAM,CAACE,GAAP,CAAWR,SAAX,EAAsB,CAAtB,EAAyBS,IAAzB,GAAgChB,KAAK,CAACoB,eAAtC;YACD;;YAEDX,UAAU,CAAC,CAAD,CAAV,CAAcO,IAAd,GAAqBhB,KAAK,CAAC8B,UAA3B;YACAvB,SAAS,GAAGC,UAAZ;UACD;QACF,CAZD,MAYO,IACLC,UAAU,CAAC,CAAD,CAAV,CAAcO,IAAd,KAAuBhB,KAAK,CAAC+B,UAA7B,IACAtB,UAAU,CAAC,CAAD,CAAV,CAAcO,IAAd,KAAuBhB,KAAK,CAACgC,cAFxB,EAGL,CACA;QACD,CALM,MAKA;UACL;QACD;MACF;;MAED,IAAIzB,SAAJ,EAAe;QACb;QACAD,KAAK,CAAC,CAAD,CAAL,CAAS2B,GAAT,GAAe,EAAC,GAAGpB,MAAM,CAACE,GAAP,CAAWR,SAAX,EAAsB,CAAtB,EAAyB2B;QAA7B,CAAf,CAFa,CAIb;;QACAxB,UAAU,GAAGG,MAAM,CAACsB,KAAP,CAAa5B,SAAb,EAAwBF,KAAxB,CAAb;QACAK,UAAU,CAAC0B,OAAX,CAAmB9B,KAAnB;QACAO,MAAM,CAACf,MAAP,CAAcS,SAAd,EAAyBF,KAAK,GAAGE,SAAR,GAAoB,CAA7C,EAAgDG,UAAhD;MACD;IACF;EACF,CA9GsC,CAgHvC;;;EACAZ,MAAM,CAACK,WAAD,EAAc,CAAd,EAAiBkC,MAAM,CAACC,iBAAxB,EAA2CzB,MAAM,CAACsB,KAAP,CAAa,CAAb,CAA3C,CAAN;EACA,OAAO,CAACvB,IAAR;AACD;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,SAASe,UAAT,CAAoBd,MAApB,EAA4B0B,UAA5B,EAAwC;EACtC,MAAMC,KAAK,GAAG3B,MAAM,CAACE,GAAP,CAAWwB,UAAX,EAAuB,CAAvB,CAAd;EACA,MAAME,OAAO,GAAG5B,MAAM,CAACE,GAAP,CAAWwB,UAAX,EAAuB,CAAvB,CAAhB;EACA,IAAIG,aAAa,GAAGH,UAAU,GAAG,CAAjC;EACA;;EACA,MAAMI,cAAc,GAAG,EAAvB;EACA9C,MAAM,CAAC2C,KAAK,CAAChB,WAAP,EAAoB,qCAApB,CAAN;EAEA,IAAIoB,SAAS,GAAGJ,KAAK,CAACrB,UAAtB;;EAEA,IAAI,CAACyB,SAAL,EAAgB;IACdA,SAAS,GAAGH,OAAO,CAACI,MAAR,CAAeL,KAAK,CAAChB,WAArB,EAAkCgB,KAAK,CAACN,KAAxC,CAAZ;;IAEA,IAAIM,KAAK,CAACM,wBAAV,EAAoC;MAClCF,SAAS,CAACE,wBAAV,GAAqC,IAArC;IACD;EACF;;EAED,MAAMC,WAAW,GAAGH,SAAS,CAAC/B,MAA9B;EACA;;EACA,MAAMT,KAAK,GAAG,EAAd;EACA;;EACA,MAAM4C,IAAI,GAAG,EAAb;EACA;;EACA,IAAIC,MAAJ;EACA;;EACA,IAAIC,QAAJ;EACA,IAAI7C,KAAK,GAAG,CAAC,CAAb;EACA;;EACA,IAAI8C,OAAO,GAAGX,KAAd;EACA,IAAIY,MAAM,GAAG,CAAb;EACA,IAAIlB,KAAK,GAAG,CAAZ;EACA,MAAMmB,MAAM,GAAG,CAACnB,KAAD,CAAf,CAhCsC,CAkCtC;EACA;;EACA,OAAOiB,OAAP,EAAgB;IACd;IACA,OAAOtC,MAAM,CAACE,GAAP,CAAW,EAAE2B,aAAb,EAA4B,CAA5B,MAAmCS,OAA1C,EAAmD,CACjD;IACD;;IAEDtD,MAAM,CACJ,CAACqD,QAAD,IAAaC,OAAO,CAACD,QAAR,KAAqBA,QAD9B,EAEJ,4BAFI,CAAN;IAIArD,MAAM,CAAC,CAACqD,QAAD,IAAaA,QAAQ,CAACI,IAAT,KAAkBH,OAAhC,EAAyC,wBAAzC,CAAN;IAEAR,cAAc,CAACY,IAAf,CAAoBb,aAApB;;IAEA,IAAI,CAACS,OAAO,CAAChC,UAAb,EAAyB;MACvB8B,MAAM,GAAGR,OAAO,CAACe,WAAR,CAAoBL,OAApB,CAAT;;MAEA,IAAI,CAACA,OAAO,CAACG,IAAb,EAAmB;QACjBL,MAAM,CAACM,IAAP,CAAYxD,KAAK,CAAC0D,GAAlB;MACD;;MAED,IAAIP,QAAJ,EAAc;QACZN,SAAS,CAACc,UAAV,CAAqBP,OAAO,CAACjB,KAA7B;MACD;;MAED,IAAIiB,OAAO,CAAC5B,2BAAZ,EAAyC;QACvCqB,SAAS,CAACe,kCAAV,GAA+C,IAA/C;MACD;;MAEDf,SAAS,CAACgB,KAAV,CAAgBX,MAAhB;;MAEA,IAAIE,OAAO,CAAC5B,2BAAZ,EAAyC;QACvCqB,SAAS,CAACe,kCAAV,GAA+C9B,SAA/C;MACD;IACF,CAlCa,CAoCd;;;IACAqB,QAAQ,GAAGC,OAAX;IACAA,OAAO,GAAGA,OAAO,CAACG,IAAlB;EACD,CA3EqC,CA6EtC;EACA;;;EACAH,OAAO,GAAGX,KAAV;;EAEA,OAAO,EAAEnC,KAAF,GAAU0C,WAAW,CAACjC,MAA7B,EAAqC;IACnC,KACE;IACAiC,WAAW,CAAC1C,KAAD,CAAX,CAAmB,CAAnB,MAA0B,MAA1B,IACA0C,WAAW,CAAC1C,KAAK,GAAG,CAAT,CAAX,CAAuB,CAAvB,MAA8B,OAD9B,IAEA0C,WAAW,CAAC1C,KAAD,CAAX,CAAmB,CAAnB,EAAsBW,IAAtB,KAA+B+B,WAAW,CAAC1C,KAAK,GAAG,CAAT,CAAX,CAAuB,CAAvB,EAA0BW,IAFzD,IAGA+B,WAAW,CAAC1C,KAAD,CAAX,CAAmB,CAAnB,EAAsB6B,KAAtB,CAA4B2B,IAA5B,KAAqCd,WAAW,CAAC1C,KAAD,CAAX,CAAmB,CAAnB,EAAsB4B,GAAtB,CAA0B4B,IALjE,EAME;MACAhE,MAAM,CAACsD,OAAD,EAAU,0BAAV,CAAN;MACAjB,KAAK,GAAG7B,KAAK,GAAG,CAAhB;MACAgD,MAAM,CAACE,IAAP,CAAYrB,KAAZ,EAHA,CAIA;;MACAiB,OAAO,CAAChC,UAAR,GAAqBU,SAArB;MACAsB,OAAO,CAACD,QAAR,GAAmBrB,SAAnB;MACAsB,OAAO,GAAGA,OAAO,CAACG,IAAlB;IACD;EACF,CAjGqC,CAmGtC;;;EACAV,SAAS,CAAC/B,MAAV,GAAmB,EAAnB,CApGsC,CAsGtC;EACA;EACA;;EACA,IAAIsC,OAAJ,EAAa;IACX;IACAA,OAAO,CAAChC,UAAR,GAAqBU,SAArB;IACAsB,OAAO,CAACD,QAAR,GAAmBrB,SAAnB;IACAhC,MAAM,CAAC,CAACsD,OAAO,CAACG,IAAV,EAAgB,wBAAhB,CAAN;EACD,CALD,MAKO;IACLD,MAAM,CAACS,GAAP;EACD,CAhHqC,CAkHtC;EACA;;;EACAzD,KAAK,GAAGgD,MAAM,CAACvC,MAAf;;EAEA,OAAOT,KAAK,EAAZ,EAAgB;IACd,MAAM8B,KAAK,GAAGY,WAAW,CAACZ,KAAZ,CAAkBkB,MAAM,CAAChD,KAAD,CAAxB,EAAiCgD,MAAM,CAAChD,KAAK,GAAG,CAAT,CAAvC,CAAd;IACA,MAAM6B,KAAK,GAAGS,cAAc,CAACmB,GAAf,EAAd;IACAjE,MAAM,CAACqC,KAAK,KAAKL,SAAX,EAAsB,yCAAtB,CAAN;IACAzB,KAAK,CAACmD,IAAN,CAAW,CAACrB,KAAD,EAAQA,KAAK,GAAGC,KAAK,CAACrB,MAAd,GAAuB,CAA/B,CAAX;IACAD,MAAM,CAACf,MAAP,CAAcoC,KAAd,EAAqB,CAArB,EAAwBC,KAAxB;EACD;;EAED/B,KAAK,CAAC2D,OAAN;EACA1D,KAAK,GAAG,CAAC,CAAT;;EAEA,OAAO,EAAEA,KAAF,GAAUD,KAAK,CAACU,MAAvB,EAA+B;IAC7BkC,IAAI,CAACI,MAAM,GAAGhD,KAAK,CAACC,KAAD,CAAL,CAAa,CAAb,CAAV,CAAJ,GAAiC+C,MAAM,GAAGhD,KAAK,CAACC,KAAD,CAAL,CAAa,CAAb,CAA1C;IACA+C,MAAM,IAAIhD,KAAK,CAACC,KAAD,CAAL,CAAa,CAAb,IAAkBD,KAAK,CAACC,KAAD,CAAL,CAAa,CAAb,CAAlB,GAAoC,CAA9C;EACD;;EAED,OAAO2C,IAAP;AACD"},"metadata":{},"sourceType":"module"}